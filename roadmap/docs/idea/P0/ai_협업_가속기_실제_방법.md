> **AI와 협업할 때 "검증 루틴"을 먼저 주고, 역할을 분리하며, 품질을 자동화 도구로 통제하는 습관**

(커머스 핵심 플로우: **로그인/장바구니/쿠폰/결제** + KPI: **검색 전환율/결제 이탈률/추천 CTR** 기준)

---

## 1) "검증 루프"를 먼저 준다

AI가 **스스로 맞는지 확인**할 수 있게(테스트/기대 결과/스크린샷/로그) *검증 수단*을 먼저 제공한다. 이게 가장 레버리지가 크다. ([Claude Code][1])

### 액션

- (결제 버그) "재현 조건 + 기대 결과 + 실패 로그 샘플"을 AI에 먼저 준다
- (쿠폰 기능) "경계값 표(0원/최소결제/중복쿠폰/최대할인)"를 먼저 준다
- (RN) "스크롤 잔렉 재현 영상/단말/OS/프레임 드랍 구간"을 먼저 준다

**예시 프롬프트**

- "아래 성공 기준을 통과해야만 완료다: (1) 테스트 통과 (2) typecheck/lint 통과 (3) 결제 flow_stage 로그에 필드 누락 0. 이 조건을 만족하는 계획부터 써라."

✅ Done: AI에게 검증 수단을 먼저 제공하는 습관이 정착됨.

---

## 2) 역할을 분리한다: 작성자 ≠ 리뷰어 ≠ 테스터 ≠ 릴리즈 매니저

한 번에 다 시키지 말고 **세션/패스로 역할을 쪼개서** 돌린다. (특히 결제/쿠폰/로그인/장바구니는 High-risk)

### 액션

- Pass A(작성): 구현 + 최소 변경
- Pass B(시니어 리뷰): "깨질 시나리오/레이스/보안/관측 누락"만 지적
- Pass C(테스터): 테스트 케이스 생성 + 누락 경계값 찾기
- Pass D(릴리즈): 플래그/롤백/모니터링 플랜 생성

> Claude Code 쪽도 "계획→검증→실행" 같은 에이전틱 워크플로에서 **검증 가능성**을 최우선으로 둔다. ([Anthropic][2])

✅ Done: High-risk 작업에서 역할 분리가 습관화됨.

---

## 3) "불변식 → 실패 시나리오 → 구현" 순서를 고정한다

커머스는 로직 정합성이 핵심이라, AI에게 **바로 코드**를 시키면 사고가 난다.
먼저 **불변식(절대 규칙)**과 **실패 시나리오(어떻게 깨지는지)**부터 뽑게 해라.

### 액션

- (쿠폰) 불변식 5개 작성 → 실패 시나리오 10개 → 그걸 테스트로 변환 → 구현
- (결제) "중복 결제/중복 이벤트/재시도/취소/인증 실패" 시나리오부터 작성

✅ Done: 구현 전에 불변식/실패 시나리오를 먼저 정의하는 루틴이 정착됨.

---

## 4) KPI 작업은 "가설"보다 "측정 설계"를 먼저 시킨다

"아이디어 10개"보다 **측정 가능한 구조**가 먼저다.
AI에게 아래 순서로 맡겨라:

### 액션

1. 퍼널 이벤트 정의
2. 필요한 필드(세그먼트/원인 분해)
3. 가드레일 지표(악화 방지)
4. 실험/릴리즈 플랜(플래그, 샘플링)

**예시**

- (검색 전환율) `search → impression → click → PDP → cart → checkout → payment` 이벤트/필드 설계
- (추천 CTR) `reco_slot_id(구좌)` 단위 노출/클릭/구매 귀속 설계
- (결제 이탈률) 실패 분류 택소노미(수단선택/인증/타임아웃/쿠폰오류/재시도) 설계

**예시 프롬프트**

- "검색 전환율을 올리고 싶다. 아이디어 말고, 이벤트 정의/필드/대시보드/가드레일 지표부터 설계해라."

✅ Done: KPI 작업 시 측정 설계가 선행됨.

---

## 5) "명확한 지시 + 출력 형식 고정"으로 품질을 안정화한다

AI 결과 품질은 재능이 아니라 **입력 규격**으로 통제한다.
OpenAI 가이드도 "명확한 지시, 원하는 형식"을 강조한다. ([OpenAI Help Center][3])

### 액션

- 항상 출력 형식을 고정:
  - `문제정의 / 가정 / 리스크 / 대안 / 선택 / 테스트 / 관측 / 롤백`
- "표준 필드"를 슬롯처럼 넣기:
  - `flow_stage, payment_method, coupon_id, is_retry, app_version, webview`

✅ Done: 출력 형식이 표준화되어 품질이 안정됨.

---

## 6) 자동화 도구를 "AI의 상사"로 만든다

AI가 만든 코드는 **도구(테스트·린트·타입체크)가 승인**하게 만들어라.
Copilot 문서도 "제안 코드를 이해/검토하고 보안·유지보수까지 고려"하라고 명시한다. ([GitHub Docs][4])

### 액션

- PR 머지 조건을 기계적으로:
  - typecheck/lint/test 실패 시 머지 불가
- High-risk(결제/쿠폰/로그인/장바구니)는:
  - "테스트 추가" 없으면 머지 불가
- AI에게는 이렇게:
  - "테스트를 먼저 추가하고, 전체 테스트 통과할 때까지 수정해라."

✅ Done: 자동화 도구가 AI 코드의 최종 승인자 역할을 함.

---

## 7) 릴리즈는 "에러율"이 아니라 "버짓 소진 속도(burn rate)"로 관리한다

커머스는 짧은 시간에 돈이 새기 때문에, **얼마나 빨리 망가지고 있는지**를 봐야 한다. Google SRE도 burn rate 기반 경보를 설명한다. ([Google SRE][5])

### 액션

- 결제/쿠폰 변경 배포 시:
  - 1%→10%→50% 롤아웃
  - 결제 실패율/결제 이탈률이 burn rate 임계치 넘으면 **자동/수동 OFF**
- AI에게 "릴리즈 런북"을 시키기:
  - "어떤 지표가 어떤 수준이면 OFF할지"를 체크리스트로 생성

✅ Done: burn rate 기반 릴리즈 관리가 정착됨.

---

## 8) 보안/민감정보는 "금지 규칙"으로 선제 봉인한다

AI에게 주는 컨텍스트가 늘수록 사고가 난다.
토큰/개인정보/결제 민감값/내부키/내부 URL은 **절대 붙여넣지 않는 규칙**을 먼저 박아라.

### 액션

- 로그/스크린샷 공유 전:
  - 이메일/전화/주소/토큰/세션값 마스킹
- WebView/딥링크 관련:
  - 허용 도메인 whitelist만 제공

✅ Done: 민감정보 금지 규칙이 팀에 정착됨.

---

## 9) "프롬프트/체크리스트를 버전 관리"해서 팀 자산화한다

개인이 잘 쓰는 AI는 의미가 작고, **팀이 재현 가능하면 임팩트**가 커진다.
Claude Code 문서도 "검증 가능한 성공 기준"이 핵심이라고 반복한다. ([Claude Code][1])

### 액션

- 레포에 `ai-playbook/` 폴더 생성
  - `high_risk_pr_review.md`
  - `kpi_measurement_design.md`
  - `checkout_failure_taxonomy.md`
- 분기마다 "좋았던 프롬프트"만 남기고, 나쁜 패턴은 삭제

✅ Done: AI 프롬프트/체크리스트가 팀 자산으로 버전 관리됨.

---

## 상황별 "지침 → 액션" 미니 예시 3개

### (A) 결제 플로우 수정 (High-risk)

- 지침 적용: **역할 분리 + 불변식 우선 + 자동화 승인 + 롤백**
- 액션:
  1. AI: 불변식 5개/실패 시나리오 10개
  2. AI: 테스트 설계(유닛/통합/E2E 최소 1)
  3. AI: PR 리뷰(레이스/중복 결제/관측 누락 체크)
  4. AI: 릴리즈 플랜(플래그/1% 롤아웃/지표 악화 시 OFF)

### (B) 검색 전환율 개선 (KPI)

- 지침 적용: **가설보다 측정 설계**
- 액션:
  1. AI: 이벤트 정의 + 필요한 필드(검색어/정렬/결과 0건/로딩시간)
  2. AI: 원인 분해 시나리오(0건/로딩/정렬/상품품질)
  3. AI: 가드레일(결제 이탈률 악화 방지)
  4. AI: 실험 플래그 + 롤아웃

### (C) 추천 CTR 올리기

- 지침 적용: **구좌(슬롯) 단위로 분해 + 관측 표준**
- 액션:
  1. AI: `reco_slot_id` 별 노출/클릭/구매 퍼널 설계
  2. AI: CTR↑인데 구매↓ 원인 체크리스트 생성
  3. AI: 로깅 필드 표준화(구좌/상품군/가격대/재고)

---

## "한 장 규칙"으로 요약

- **High-risk(결제/쿠폰/로그인/장바구니)**: `불변식 → 실패시나리오 → 테스트 → 구현 → 시니어리뷰(AI) → 관측/롤백`
- **KPI(검색 전환/결제 이탈/추천 CTR)**: `측정 설계(이벤트/필드/가드레일) → 실험/롤아웃 → 모니터링/중단 조건`

---

## 템플릿 3개 (복붙 형태)

1. High-risk PR용 **AI 리뷰 프롬프트** (결제/쿠폰/로그인/장바구니 공통)
2. KPI용 **측정 설계 프롬프트** (검색 전환/추천 CTR/결제 이탈률 공통)
3. 릴리즈용 **플래그·롤아웃·OFF 조건 프롬프트** (burn rate 포함) ([Google SRE][5])

[1]: https://code.claude.com/docs/en/best-practices?utm_source=chatgpt.com "Best Practices for Claude Code - Claude Code Docs"
[2]: https://www.anthropic.com/engineering/claude-code-best-practices?utm_source=chatgpt.com "Claude Code: Best practices for agentic coding"
[3]: https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api?utm_source=chatgpt.com "Best practices for prompt engineering with the OpenAI API"
[4]: https://docs.github.com/en/copilot/get-started/best-practices?utm_source=chatgpt.com "Best practices for using GitHub Copilot"
[5]: https://sre.google/workbook/alerting-on-slos/?utm_source=chatgpt.com "Prometheus Alerting: Turn SLOs into Alerts"
